rare_earths[2,] <- gsub("NA_","",rare_earths[2,])
rare_earths[2,] <- gsub("_NA", "",rare_earths[2,])
#renaming column X11
rare_earths[2,11]<- "REE_Mineralogy"
#replacing empty cells in column 1 with NA
rare_earths[,1] <- gsub(" ", NA ,rare_earths[,1])
#replacing NAs by the last non-NA value that came before
rare_earths$X1 <-na.locf(rare_earths$X1)
##source: http://stackoverflow.com/questions/20416046/filling-data-frame-with-previous-row-value
table(is.na(rare_earths$X1))
#column 1 does not have any NA anymore
##remove first row and last column (empty)
rare_earths <- rare_earths[-1,]
rare_earths <- select(rare_earths, -(X25))
#refactor to remove all rows that are all NA, omitting the first column
#based on http://stackoverflow.com/questions/6471689/remove-rows-in-r-matrix-where-all-data-is-na
rare_earths <-rare_earths[rowSums(is.na(rare_earths)) != (ncol(rare_earths)-1),]
#get names from first row and make them row names, remove first row
rare_earth_names <- as.character(rare_earths[1,])
colnames(rare_earths) <- rare_earth_names
rare_earths<-rare_earths[-1,]
#tidying up colnames, replacing whitespace with _
whitespace <- " "
rare_earth_names <-lapply(rare_earth_names, function(x) {str_replace_all(x, pattern=whitespace, replacement = "_")})
colnames(rare_earths) <- rare_earth_names
### use this cleaned dataframe for the Leaflet scripts
View(rare_earths)
library(xlsx)
library(plyr)
library(dplyr)
library(stringr)
#reading file
rare_earths <- read.xlsx("of02-189.xls", sheetName="Sheet1", header = FALSE)
#change variables from factor to character
rare_earths[]<-lapply(rare_earths, as.character)
#row 2 contains the relevant column names, adding Deposit_Type and transferring some names from row 1
rare_earths[2,1]<- "Deposit_Type"
#selecting relevant columns
rare_earths[2,'X15'] <- rare_earths[1,'X15']
rare_earths[2,'X16'] <- rare_earths[1,'X16']
rare_earths[2,'X17'] <- rare_earths[1,'X17']
rare_earths[2,'X18'] <- rare_earths[1,'X18']
##note: could refactor this using apply or dplyr package
#replacing blanks with NA in column X1
rare_earths[13,'X1'] <- NA
rare_earths[76,'X1'] <- NA
##note: could refactor as well to make it more general
#replacing NAs by the last non-NA value that came before
rare_earths$X1 <-na.locf(rare_earths$X1)
##source: http://stackoverflow.com/questions/20416046/filling-data-frame-with-previous-row-value
table(is.na(rare_earths$X1))
#column 1 does not have any NA anymore
##remove first row
rare_earths<-rare_earths[-1,]
#refactor to remove all rows that are all NA, omitting the first column
#based on http://stackoverflow.com/questions/6471689/remove-rows-in-r-matrix-where-all-data-is-na
rare_earths <-rare_earths[rowSums(is.na(rare_earths)) != (ncol(rare_earths)-1),]
#get names from first row and make them row names, remove used row
rare_earth_names <- as.character(rare_earths[1,])
colnames(rare_earths) <- rare_earth_names
#tidying up colnames
whitespace <- " "
rare_earth_names <-lapply(rare_earth_names, function(x) {str_replace_all(x, pattern=whitespace, replacement = "_")})
colnames(rare_earths) <- rare_earth_names
#removing first row
rare_earths<-rare_earths[-1,]
### use this cleaned dataframe for the Leaflet scripts
View(rare_earths)
library(xlsx)
library(plyr)
library(dplyr)
library(stringr)
#reading file
rare_earths <- read.xlsx("of02-189.xls", sheetName="Sheet1", header = FALSE)
#change variables from factor to character
rare_earths[]<-lapply(rare_earths, as.character)
#row 2 contains the relevant column names, adding Deposit_Type and transferring some names from row 1
rare_earths[2,1]<- "Deposit_Type"
#selecting relevant columns
rare_earths[2,'X15'] <- rare_earths[1,'X15']
rare_earths[2,'X16'] <- rare_earths[1,'X16']
rare_earths[2,'X17'] <- rare_earths[1,'X17']
rare_earths[2,'X18'] <- rare_earths[1,'X18']
##note: could refactor this using apply or dplyr package
#replacing blanks with NA in column X1
rare_earths[13,'X1'] <- NA
rare_earths[76,'X1'] <- NA
##note: could refactor as well to make it more general
#replacing NAs by the last non-NA value that came before
rare_earths$X1 <-na.locf(rare_earths$X1)
##source: http://stackoverflow.com/questions/20416046/filling-data-frame-with-previous-row-value
table(is.na(rare_earths$X1))
#column 1 does not have any NA anymore
##remove first row
rare_earths<-rare_earths[-1,]
#refactor to remove all rows that are all NA, omitting the first column
#based on http://stackoverflow.com/questions/6471689/remove-rows-in-r-matrix-where-all-data-is-na
rare_earths <-rare_earths[rowSums(is.na(rare_earths)) != (ncol(rare_earths)-1),]
#get names from first row and make them row names, remove used row
rare_earth_names <- as.character(rare_earths[1,])
colnames(rare_earths) <- rare_earth_names
#tidying up colnames
whitespace <- " "
rare_earth_names <-lapply(rare_earth_names, function(x) {str_replace_all(x, pattern=whitespace, replacement = "_")})
colnames(rare_earths) <- rare_earth_names
#removing first row
rare_earths<-rare_earths[-1,]
### use this cleaned dataframe for the Leaflet scripts
View(rare_earths)
?na.locf
library(zoo)
library(xlsx)
library(plyr)
library(dplyr)
library(stringr)
library(zoo)
#reading file
rare_earths <- read.xlsx("of02-189.xls", sheetName="Sheet1", header = FALSE)
#change variables from factor to character
rare_earths[]<-lapply(rare_earths, as.character)
#row 2 contains the relevant column names, adding Deposit_Type and transferring some names from row 1
rare_earths[2,1]<- "Deposit_Type"
#selecting relevant columns
rare_earths[2,'X15'] <- rare_earths[1,'X15']
rare_earths[2,'X16'] <- rare_earths[1,'X16']
rare_earths[2,'X17'] <- rare_earths[1,'X17']
rare_earths[2,'X18'] <- rare_earths[1,'X18']
##note: could refactor this using apply or dplyr package
#replacing blanks with NA in column X1
rare_earths[13,'X1'] <- NA
rare_earths[76,'X1'] <- NA
##note: could refactor as well to make it more general
#replacing NAs by the last non-NA value that came before
rare_earths$X1 <-na.locf(rare_earths$X1)
##source: http://stackoverflow.com/questions/20416046/filling-data-frame-with-previous-row-value
table(is.na(rare_earths$X1))
#column 1 does not have any NA anymore
##remove first row
rare_earths<-rare_earths[-1,]
#refactor to remove all rows that are all NA, omitting the first column
#based on http://stackoverflow.com/questions/6471689/remove-rows-in-r-matrix-where-all-data-is-na
rare_earths <-rare_earths[rowSums(is.na(rare_earths)) != (ncol(rare_earths)-1),]
#get names from first row and make them row names, remove used row
rare_earth_names <- as.character(rare_earths[1,])
colnames(rare_earths) <- rare_earth_names
#tidying up colnames
whitespace <- " "
rare_earth_names <-lapply(rare_earth_names, function(x) {str_replace_all(x, pattern=whitespace, replacement = "_")})
colnames(rare_earths) <- rare_earth_names
#removing first row
rare_earths<-rare_earths[-1,]
### use this cleaned dataframe for the Leaflet scripts
rm(rare_earths)
setwd("~/Desktop/DDL_USGS_project")
library(xlsx)
library(plyr)
library(dplyr)
library(stringr)
library(zoo)
#reading file
rare_earths <- read.csv("of02-189.csv", header = TRUE)
#change variables from factor to character
rare_earths[]<-lapply(rare_earths, as.character)
#row 2 contains the relevant column names, adding Deposit_Type and transferring some names from row 1
rare_earths[2,1]<- "Deposit_Type"
#selecting relevant columns
rare_earths[2,'X15'] <- rare_earths[1,'X15']
rare_earths[2,'X16'] <- rare_earths[1,'X16']
rare_earths[2,'X17'] <- rare_earths[1,'X17']
rare_earths[2,'X18'] <- rare_earths[1,'X18']
##note: could refactor this using apply or dplyr package
#replacing blanks with NA in column X1
rare_earths[13,'X1'] <- NA
rare_earths[76,'X1'] <- NA
##note: could refactor as well to make it more general
#replacing NAs by the last non-NA value that came before
rare_earths$X1 <-na.locf(rare_earths$X1)
##source: http://stackoverflow.com/questions/20416046/filling-data-frame-with-previous-row-value
table(is.na(rare_earths$X1))
#column 1 does not have any NA anymore
##remove first row
rare_earths<-rare_earths[-1,]
#refactor to remove all rows that are all NA, omitting the first column
#based on http://stackoverflow.com/questions/6471689/remove-rows-in-r-matrix-where-all-data-is-na
rare_earths <-rare_earths[rowSums(is.na(rare_earths)) != (ncol(rare_earths)-1),]
#get names from first row and make them row names, remove used row
rare_earth_names <- as.character(rare_earths[1,])
colnames(rare_earths) <- rare_earth_names
#tidying up colnames
whitespace <- " "
rare_earth_names <-lapply(rare_earth_names, function(x) {str_replace_all(x, pattern=whitespace, replacement = "_")})
colnames(rare_earths) <- rare_earth_names
#removing first row
rare_earths<-rare_earths[-1,]
### use this cleaned dataframe for the Leaflet scripts
View(rare_earths)
View(rare_earths)
library(xlsx)
library(plyr)
library(dplyr)
library(stringr)
library(zoo)
#reading file
rare_earths <- read.csv("of02-189.csv", header = TRUE)
#change variables from factor to character
rare_earths[]<-lapply(rare_earths, as.character)
#row 2 contains the relevant column names, adding Deposit_Type and transferring some names from row 1
rare_earths[2,1]<- "Deposit_Type"
#selecting relevant columns
rare_earths[2,'X15'] <- rare_earths[1,'X15']
rare_earths[2,'X16'] <- rare_earths[1,'X16']
rare_earths[2,'X17'] <- rare_earths[1,'X17']
rare_earths[2,'X18'] <- rare_earths[1,'X18']
##note: could refactor this using apply or dplyr package
#replacing blanks with NA in column X1
rare_earths[13,'X1'] <- NA
rare_earths[76,'X1'] <- NA
##note: could refactor as well to make it more general
#replacing NAs by the last non-NA value that came before
rare_earths$X1 <-na.locf(rare_earths$X1)
##source: http://stackoverflow.com/questions/20416046/filling-data-frame-with-previous-row-value
table(is.na(rare_earths$X1))
#column 1 does not have any NA anymore
##remove first row
rare_earths<-rare_earths[-1,]
#refactor to remove all rows that are all NA, omitting the first column
#based on http://stackoverflow.com/questions/6471689/remove-rows-in-r-matrix-where-all-data-is-na
rare_earths <-rare_earths[rowSums(is.na(rare_earths)) != (ncol(rare_earths)-1),]
#get names from first row and make them row names, remove used row
rare_earth_names <- as.character(rare_earths[1,])
colnames(rare_earths) <- rare_earth_names
#tidying up colnames
whitespace <- " "
rare_earth_names <-lapply(rare_earth_names, function(x) {str_replace_all(x, pattern=whitespace, replacement = "_")})
colnames(rare_earths) <- rare_earth_names
#removing first row
rare_earths<-rare_earths[-1,]
### use this cleaned dataframe for the Leaflet scripts
write.csv(rare_earths, file = "rare_earths.csv", row.names = FALSE)
View(rare_earths)
rare_earths <- read.csv("rare_earths.csv", header = TRUE)
setwd("~/Desktop/DDL_USGS_project")
library(rgdal)
library(leaflet)
library(plyr)
library(dplyr)
library(countrycode)
## code adapted from http://adolfoalvarez.cl/code/users.html
## using rare_earths dataframe from script "of02-189_wrangled copy-2.R" saved as rare_earths.csv
rare_earths <- read.csv("rare_earths.csv", header = TRUE)
# We download the data for the map from naturalearthdata.com
url <- "http://www.naturalearthdata.com/http//www.naturalearthdata.com/download/50m/cultural/ne_50m_admin_0_countries.zip"
folder <- getwd() #set a folder where to download and extract the data
file <- basename(url)
# download.file(url, file)
# unzip(file, exdir = folder)
#And read it with rgdal library
#change working directory to directory that contains ne_50m_admin_0_countries
world <- readOGR(dsn = folder,
layer = "ne_50m_admin_0_countries",
#encoding = "latin1", #you may need to use a different encoding
verbose = FALSE)
#select useful columns from rare_earths
rare_earths_country<-select(rare_earths, Deposit_or_district_name, Country, STATUS)
#convert the country name to a country code
rare_earths_country$Code <- countrycode(rare_earths_country$Country, "country.name", "iso3c")
#Group by country and count the number of Projects per country
rare_earths_country2 <- ddply(rare_earths_country, .(Code), summarize, projects = length(Code))
#We need to reconvert to data.frame to merge it with the SpatialPolygons data frame "world"
rare_earths_country3  <- data.frame(rare_earths_country2)
names(rare_earths_country3) = c("country", "projects")
world <- sp::merge(world, rare_earths_country3,
by.x = "iso_a3",
by.y = "country",
sort = FALSE)
#Tiles coming from stamen.com
tiles <- "http://{s}.tile.stamen.com/toner-lite/{z}/{x}/{y}.png"
attribution <- 'Map tiles by <a href="http://stamen.com">Stamen Design</a>, under <a href="http://creativecommons.org/licenses/by/3.0">CC BY 3.0</a>. Map data by <a href="http://www.naturalearthdata.com/">Natural Earth</a>.'
shiny::runApp('~/Desktop/ddl_geo_map_test')
setwd("~/Desktop/DDL_USGS_project/ne_50m_admin_0_countries ")
library(rgdal)
library(leaflet)
library(plyr)
library(dplyr)
library(countrycode)
## code adapted from http://adolfoalvarez.cl/code/users.html
## using rare_earths dataframe from script "of02-189_wrangled copy-2.R" saved as rare_earths.csv
## set working directory to folder "ne_50m_admin_0_countries"
rare_earths <- read.csv("rare_earths.csv", header = TRUE)
# We download the data for the map from naturalearthdata.com
url <- "http://www.naturalearthdata.com/http//www.naturalearthdata.com/download/50m/cultural/ne_50m_admin_0_countries.zip"
folder <- getwd() #set a folder where to download and extract the data
file <- basename(url)
#download.file(url, file)
#unzip(file, exdir = folder)
#And read it with rgdal library
#change working directory to directory that contains ne_50m_admin_0_countries
world <- readOGR(dsn = folder,
layer = "ne_50m_admin_0_countries",
#encoding = "latin1", #you may need to use a different encoding
verbose = FALSE)
#select useful columns from rare_earths
rare_earths_country<-select(rare_earths, Deposit_or_district_name, Country, STATUS)
#convert the country name to a country code
rare_earths_country$Code <- countrycode(rare_earths_country$Country, "country.name", "iso3c")
#Group by country and count the number of Projects per country
rare_earths_country2 <- ddply(rare_earths_country, .(Code), summarize, projects = length(Code))
#We need to reconvert to data.frame to merge it with the SpatialPolygons data frame "world"
rare_earths_country3  <- data.frame(rare_earths_country2)
names(rare_earths_country3) = c("country", "projects")
world <- sp::merge(world, rare_earths_country3,
by.x = "iso_a3",
by.y = "country",
sort = FALSE)
#Tiles coming from stamen.com
tiles <- "http://{s}.tile.stamen.com/toner-lite/{z}/{x}/{y}.png"
attribution <- 'Map tiles by <a href="http://stamen.com">Stamen Design</a>, under <a href="http://creativecommons.org/licenses/by/3.0">CC BY 3.0</a>. Map data by <a href="http://www.naturalearthdata.com/">Natural Earth</a>.'
##################################################################################################################
library(rgdal)
library(leaflet)
library(plyr)
library(dplyr)
library(countrycode)
## code adapted from http://adolfoalvarez.cl/code/users.html
## using rare_earths dataframe from script "of02-189_wrangled copy-2.R" saved as rare_earths.csv
## set working directory to folder "ne_50m_admin_0_countries"
rare_earths <- read.csv("rare_earths.csv", header = TRUE)
# We download the data for the map from naturalearthdata.com
url <- "http://www.naturalearthdata.com/http//www.naturalearthdata.com/download/50m/cultural/ne_50m_admin_0_countries.zip"
folder <- getwd() #set a folder where to download and extract the data
file <- basename(url)
#download.file(url, file)
#unzip(file, exdir = folder)
#And read it with rgdal library
#change working directory to directory that contains ne_50m_admin_0_countries
world <- readOGR(dsn = folder,
layer = "ne_50m_admin_0_countries",
#encoding = "latin1", #you may need to use a different encoding
verbose = FALSE)
#select useful columns from rare_earths
rare_earths_country<-select(rare_earths, Deposit_or_district_name, Country, STATUS)
#convert the country name to a country code
rare_earths_country$Code <- countrycode(rare_earths_country$Country, "country.name", "iso3c")
#Group by country and count the number of Projects per country
rare_earths_country2 <- ddply(rare_earths_country, .(Code), summarize, projects = length(Code))
#We need to reconvert to data.frame to merge it with the SpatialPolygons data frame "world"
rare_earths_country3  <- data.frame(rare_earths_country2)
names(rare_earths_country3) = c("country", "projects")
world <- sp::merge(world, rare_earths_country3,
by.x = "iso_a3",
by.y = "country",
sort = FALSE)
#Tiles coming from stamen.com
tiles <- "http://{s}.tile.stamen.com/toner-lite/{z}/{x}/{y}.png"
attribution <- 'Map tiles by <a href="http://stamen.com">Stamen Design</a>, under <a href="http://creativecommons.org/licenses/by/3.0">CC BY 3.0</a>. Map data by <a href="http://www.naturalearthdata.com/">Natural Earth</a>.'
##################################################################################################################
shiny::runApp('~/Desktop/ddl_geo_map_test')
library(xlsx)
library(stringr)
library(dplyr)
library(leaflet)
#reading in dataset from UPenn
ddl_geo_data <- read.xlsx("ddl_geo_data.xlsx", sheetName = "Sheet1",  header =TRUE)
#transforming all variables to char
ddl_geo_data[]<-lapply(ddl_geo_data, as.character)
#renaming 'Not available' to NA
ddl_geo_data[ddl_geo_data == "Not Available"] <- NA
##removing duplicates
#reference: http://www.cookbook-r.com/Manipulating_data/Finding_and_removing_duplicate_records/
ddl_geo_data <- ddl_geo_data[!duplicated(ddl_geo_data$DEPOSIT.NAME),]
#extracting REE elements from all rows of column 'REEs'
new_list <- (strsplit(as.character(ddl_geo_data$REEs),',', fixed=FALSE))
new_list2 <- unlist (new_list)
#removing whitespace
new_list3 <- str_replace_all(new_list2, fixed(" "), "")
#checking which elements are unique
new_list4 <- unique(new_list3)
#removing by hand strings that contain misspellings
new_list5 <-new_list4[-c(1,17,18,19,20)]
##this generates a list of all the different elements found in the different mines
#generating dataframes that indicate the presence or absence of an element in every mine
q <- data.frame()
for (i in new_list5) {
for (j in 1:nrow(ddl_geo_data)) {
if (grepl(i, ddl_geo_data$REEs[j]) == TRUE) {
q <- rbind(q,as.data.frame(cbind(ddl_geo_data$DEPOSIT.NAME[j],ddl_geo_data$LATITUDE[j],ddl_geo_data$LONGITUDE[j],(as.character(i)), as.numeric(1))))
}
}
}
mines_present_elements <- q
q<-select(q,V1:V4)
colnames(q) <- c("Mines", "lat", "lon", "Element")
#http://stackoverflow.com/questions/3418128/how-to-convert-a-factor-to-an-integer-numeric-without-a-loss-of-information
q$lat<-as.numeric(levels(q$lat))[q$lat]
q$lon<-as.numeric(levels(q$lon))[q$lon]
#loop to separate markers (move them by 100m)
#+(runif(1)-0.5)/750
#sort dataframe by location
q<-ungroup(q)
#adjust coordinates by 50m, try more!
#https://gist.github.com/avioing/873142
q2<-mutate(q, lat= lat+(runif(nrow(q))-0.5)/750, lon = lon+(runif(nrow(q))-0.5)/750)
q3<-arrange(q2,Mines)
##################################################################################################################
library(xlsx)
library(stringr)
library(dplyr)
library(leaflet)
#reading in dataset from UPenn
ddl_geo_data <- read.xlsx("ddl_geo_data.xlsx", sheetName = "Sheet1",  header =TRUE)
#transforming all variables to char
ddl_geo_data[]<-lapply(ddl_geo_data, as.character)
#renaming 'Not available' to NA
ddl_geo_data[ddl_geo_data == "Not Available"] <- NA
##removing duplicates
#reference: http://www.cookbook-r.com/Manipulating_data/Finding_and_removing_duplicate_records/
ddl_geo_data <- ddl_geo_data[!duplicated(ddl_geo_data$DEPOSIT.NAME),]
#extracting REE elements from all rows of column 'REEs'
new_list <- (strsplit(as.character(ddl_geo_data$REEs),',', fixed=FALSE))
new_list2 <- unlist (new_list)
#removing whitespace
new_list3 <- str_replace_all(new_list2, fixed(" "), "")
#checking which elements are unique
new_list4 <- unique(new_list3)
#removing by hand strings that contain misspellings
new_list5 <-new_list4[-c(1,17,18,19,20)]
##this generates a list of all the different elements found in the different mines
#generating dataframes that indicate the presence or absence of an element in every mine
q <- data.frame()
for (i in new_list5) {
for (j in 1:nrow(ddl_geo_data)) {
if (grepl(i, ddl_geo_data$REEs[j]) == TRUE) {
q <- rbind(q,as.data.frame(cbind(ddl_geo_data$DEPOSIT.NAME[j],ddl_geo_data$LATITUDE[j],ddl_geo_data$LONGITUDE[j],(as.character(i)), as.numeric(1))))
}
}
}
mines_present_elements <- q
q<-select(q,V1:V4)
colnames(q) <- c("Mines", "lat", "lon", "Element")
#http://stackoverflow.com/questions/3418128/how-to-convert-a-factor-to-an-integer-numeric-without-a-loss-of-information
q$lat<-as.numeric(levels(q$lat))[q$lat]
q$lon<-as.numeric(levels(q$lon))[q$lon]
#loop to separate markers (move them by 100m)
#+(runif(1)-0.5)/750
#sort dataframe by location
q<-ungroup(q)
#adjust coordinates by 50m, try more!
#https://gist.github.com/avioing/873142
q2<-mutate(q, lat= lat+(runif(nrow(q))-0.5)/750, lon = lon+(runif(nrow(q))-0.5)/750)
q3<-arrange(q2,Mines)
library(xlsx)
library(stringr)
library(dplyr)
library(leaflet)
#reading in dataset from UPenn
ddl_geo_data <- read.xlsx("ddl_geo_data.xlsx", sheetName = "Sheet1",  header =TRUE)
#transforming all variables to char
ddl_geo_data[]<-lapply(ddl_geo_data, as.character)
#renaming 'Not available' to NA
ddl_geo_data[ddl_geo_data == "Not Available"] <- NA
##removing duplicates
#reference: http://www.cookbook-r.com/Manipulating_data/Finding_and_removing_duplicate_records/
ddl_geo_data <- ddl_geo_data[!duplicated(ddl_geo_data$DEPOSIT.NAME),]
#extracting REE elements from all rows of column 'REEs'
new_list <- (strsplit(as.character(ddl_geo_data$REEs),',', fixed=FALSE))
new_list2 <- unlist (new_list)
#removing whitespace
new_list3 <- str_replace_all(new_list2, fixed(" "), "")
#checking which elements are unique
new_list4 <- unique(new_list3)
#removing by hand strings that contain misspellings
new_list5 <-new_list4[-c(1,17,18,19,20)]
##this generates a list of all the different elements found in the different mines
#generating dataframes that indicate the presence or absence of an element in every mine
q <- data.frame()
for (i in new_list5) {
for (j in 1:nrow(ddl_geo_data)) {
if (grepl(i, ddl_geo_data$REEs[j]) == TRUE) {
q <- rbind(q,as.data.frame(cbind(ddl_geo_data$DEPOSIT.NAME[j],ddl_geo_data$LATITUDE[j],ddl_geo_data$LONGITUDE[j],(as.character(i)), as.numeric(1))))
}
}
}
mines_present_elements <- q
q<-select(q,V1:V4)
colnames(q) <- c("Mines", "lat", "lon", "Element")
#http://stackoverflow.com/questions/3418128/how-to-convert-a-factor-to-an-integer-numeric-without-a-loss-of-information
q$lat<-as.numeric(levels(q$lat))[q$lat]
q$lon<-as.numeric(levels(q$lon))[q$lon]
#loop to separate markers (move them by 100m)
#+(runif(1)-0.5)/750
#sort dataframe by location
q<-ungroup(q)
#adjust coordinates by 50m, try more!
#https://gist.github.com/avioing/873142
q2<-mutate(q, lat= lat+(runif(nrow(q))-0.5)/750, lon = lon+(runif(nrow(q))-0.5)/750)
q3<-arrange(q2,Mines)
ddl <- read.xlsx("ddl_geo_data.xlsx", sheetName="Sheet1", header = TRUE)
write.csv(ddl, file = "ddl_geo_data.csv", row.names = FALSE)
rm(ddl)
shiny::runApp('~/Desktop/ddl_geo_map_test')
setwd("~/Desktop/DDL_USGS_project/ne_50m_admin_0_countries ")
setwd("~/Desktop/DDL_USGS_project/ne_50m_admin_0_countries ")
shiny::runApp('~/Desktop/DDL_USGS_project')
shiny::runApp('~/Desktop/DDL_USGS_project')
shiny::runApp('~/Desktop/DDL_USGS_project')
shiny::runApp('~/Desktop/DDL_USGS_project')
shiny::runApp('~/Desktop/DDL_USGS_project')
setwd("~/Desktop/DDL_USGS_project/ne_50m_admin_0_countries ")
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
